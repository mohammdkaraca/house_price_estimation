{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6b2d710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Import Models\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d8a31a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for binary classification metrics: 2300000.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20131 entries, 0 to 20130\n",
      "Data columns (total 65 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   Net_Metrekare                         20131 non-null  int64  \n",
      " 1   Brüt_Metrekare                        20131 non-null  float64\n",
      " 2   Oda_Sayısı                            20131 non-null  float64\n",
      " 3   Fiyat                                 20131 non-null  float64\n",
      " 4   Binanın_Kat_Sayısı                    20131 non-null  int64  \n",
      " 5   Banyo_Sayısı                          20131 non-null  float64\n",
      " 6   Bulunduğu_Kat_1.Kat                   20131 non-null  int64  \n",
      " 7   Bulunduğu_Kat_10.Kat                  20131 non-null  int64  \n",
      " 8   Bulunduğu_Kat_11.Kat                  20131 non-null  int64  \n",
      " 9   Bulunduğu_Kat_12.Kat                  20131 non-null  int64  \n",
      " 10  Bulunduğu_Kat_13.Kat                  20131 non-null  int64  \n",
      " 11  Bulunduğu_Kat_14.Kat                  20131 non-null  int64  \n",
      " 12  Bulunduğu_Kat_15.Kat                  20131 non-null  int64  \n",
      " 13  Bulunduğu_Kat_16.Kat                  20131 non-null  int64  \n",
      " 14  Bulunduğu_Kat_17.Kat                  20131 non-null  int64  \n",
      " 15  Bulunduğu_Kat_18.Kat                  20131 non-null  int64  \n",
      " 16  Bulunduğu_Kat_19.Kat                  20131 non-null  int64  \n",
      " 17  Bulunduğu_Kat_2.Kat                   20131 non-null  int64  \n",
      " 18  Bulunduğu_Kat_21.Kat                  20131 non-null  int64  \n",
      " 19  Bulunduğu_Kat_22.Kat                  20131 non-null  int64  \n",
      " 20  Bulunduğu_Kat_26.Kat                  20131 non-null  int64  \n",
      " 21  Bulunduğu_Kat_3.Kat                   20131 non-null  int64  \n",
      " 22  Bulunduğu_Kat_30.Kat                  20131 non-null  int64  \n",
      " 23  Bulunduğu_Kat_4.Kat                   20131 non-null  int64  \n",
      " 24  Bulunduğu_Kat_40+.Kat                 20131 non-null  int64  \n",
      " 25  Bulunduğu_Kat_5.Kat                   20131 non-null  int64  \n",
      " 26  Bulunduğu_Kat_6.Kat                   20131 non-null  int64  \n",
      " 27  Bulunduğu_Kat_7.Kat                   20131 non-null  int64  \n",
      " 28  Bulunduğu_Kat_8.Kat                   20131 non-null  int64  \n",
      " 29  Bulunduğu_Kat_9.Kat                   20131 non-null  int64  \n",
      " 30  Bulunduğu_Kat_Bilinmiyor              20131 non-null  int64  \n",
      " 31  Bulunduğu_Kat_Bodrum Kat              20131 non-null  int64  \n",
      " 32  Bulunduğu_Kat_Düz Giriş (Zemin)       20131 non-null  int64  \n",
      " 33  Bulunduğu_Kat_Çatı Katı               20131 non-null  int64  \n",
      " 34  Binanın_Yaşı_0 (Yeni)                 20131 non-null  int64  \n",
      " 35  Binanın_Yaşı_1                        20131 non-null  int64  \n",
      " 36  Binanın_Yaşı_11-15                    20131 non-null  int64  \n",
      " 37  Binanın_Yaşı_16-20                    20131 non-null  int64  \n",
      " 38  Binanın_Yaşı_2                        20131 non-null  int64  \n",
      " 39  Binanın_Yaşı_21 Ve Üzeri              20131 non-null  int64  \n",
      " 40  Binanın_Yaşı_3                        20131 non-null  int64  \n",
      " 41  Binanın_Yaşı_4                        20131 non-null  int64  \n",
      " 42  Binanın_Yaşı_5-10                     20131 non-null  int64  \n",
      " 43  Isıtma_Tipi_Diğer                     20131 non-null  int64  \n",
      " 44  Isıtma_Tipi_Doğalgaz Sobalı           20131 non-null  int64  \n",
      " 45  Isıtma_Tipi_Güneş Enerjisi            20131 non-null  int64  \n",
      " 46  Isıtma_Tipi_Isıtma Yok                20131 non-null  int64  \n",
      " 47  Isıtma_Tipi_Jeotermal                 20131 non-null  int64  \n",
      " 48  Isıtma_Tipi_Kat Kaloriferi            20131 non-null  int64  \n",
      " 49  Isıtma_Tipi_Klimalı                   20131 non-null  int64  \n",
      " 50  Isıtma_Tipi_Kombi Doğalgaz            20131 non-null  int64  \n",
      " 51  Isıtma_Tipi_Merkezi (Pay Ölçer)       20131 non-null  int64  \n",
      " 52  Isıtma_Tipi_Merkezi Doğalgaz          20131 non-null  int64  \n",
      " 53  Isıtma_Tipi_Merkezi Kömür             20131 non-null  int64  \n",
      " 54  Isıtma_Tipi_Sobalı                    20131 non-null  int64  \n",
      " 55  Isıtma_Tipi_Yerden Isıtma             20131 non-null  int64  \n",
      " 56  Kullanım_Durumu_Boş                   20131 non-null  int64  \n",
      " 57  Kullanım_Durumu_Kiracı Oturuyor       20131 non-null  int64  \n",
      " 58  Kullanım_Durumu_Mülk Sahibi Oturuyor  20131 non-null  int64  \n",
      " 59  Tapu_Durumu_Arsa Tapulu               20131 non-null  int64  \n",
      " 60  Tapu_Durumu_Bilinmiyor                20131 non-null  int64  \n",
      " 61  Tapu_Durumu_Hisseli Tapu              20131 non-null  int64  \n",
      " 62  Tapu_Durumu_Kat Mülkiyeti             20131 non-null  int64  \n",
      " 63  Tapu_Durumu_Kat İrtifakı              20131 non-null  int64  \n",
      " 64  Tapu_Durumu_Müstakil Tapulu           20131 non-null  int64  \n",
      "dtypes: float64(4), int64(61)\n",
      "memory usage: 10.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "file_path = 'home_price_cleaned_OHE.csv'  # CHANGE THIS to your filename\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define features and target\n",
    "# Assuming the target column is named 'Price'. Change if necessary.\n",
    "target_col = 'Fiyat' \n",
    "\n",
    "X = df.drop('Fiyat',axis =1)\n",
    "y = df['Fiyat']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling (Important for Lasso and MLP)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Calculate the threshold for classification metrics (e.g., Median Price)\n",
    "binary_threshold = y_train.median()\n",
    "print(f\"Threshold for binary classification metrics: {binary_threshold}\")\n",
    "df.shape\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c1628ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global list to store results\n",
    "results_list = []\n",
    "\n",
    "# --- Evaluation Function (Using the 3 Metrics) ---\n",
    "def evaluate_and_log(model_name, tuning_method, model, X_test, y_test):\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate Metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"--- {model_name} ({tuning_method}) ---\")\n",
    "    print(f\"  R² Score: {r2:.4f}\")\n",
    "    print(f\"  MAE:      {mae:,.0f}\")\n",
    "    print(f\"  RMSE:     {rmse:,.0f}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    results_list.append({\n",
    "        'Model': model_name,\n",
    "        'Tuning': tuning_method,\n",
    "        'R2': r2,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'Best Params': model.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4a2c6c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Lasso (Bayesian)...\n",
      "--- Lasso (Bayesian) ---\n",
      "  R² Score: 0.3784\n",
      "  MAE:      1,323,480\n",
      "  RMSE:     3,088,880\n",
      "------------------------------\n",
      "Training Lasso (Grid Search)...\n",
      "--- Lasso (Grid Search) ---\n",
      "  R² Score: 0.3784\n",
      "  MAE:      1,323,480\n",
      "  RMSE:     3,088,880\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Lasso: Bayesian Optimization ---\n",
    "lasso_bayes_params = {\n",
    "    'alpha': Real(0.001, 10.0, prior='log-uniform'), # Strength of regularization\n",
    "    'selection': Categorical(['cyclic', 'random'])\n",
    "}\n",
    "\n",
    "opt_lasso = BayesSearchCV(\n",
    "    Lasso(random_state=42),\n",
    "    lasso_bayes_params,\n",
    "    n_iter=20, cv=3, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Lasso (Bayesian)...\")\n",
    "opt_lasso.fit(X_train, y_train)\n",
    "evaluate_and_log(\"Lasso\", \"Bayesian\", opt_lasso, X_test, y_test)\n",
    "\n",
    "# --- Lasso: Grid Search ---\n",
    "lasso_grid_params = {\n",
    "    'alpha': [0.01, 0.1, 1, 5, 10],\n",
    "    'selection': ['cyclic', 'random']\n",
    "}\n",
    "\n",
    "grid_lasso = GridSearchCV(\n",
    "    Lasso(random_state=42),\n",
    "    lasso_grid_params,\n",
    "    cv=3, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Lasso (Grid Search)...\")\n",
    "grid_lasso.fit(X_train, y_train)\n",
    "evaluate_and_log(\"Lasso\", \"Grid Search\", grid_lasso, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "37e85aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree (Bayesian)...\n",
      "--- Decision Tree (Bayesian) ---\n",
      "  R² Score: -0.0003\n",
      "  MAE:      3,588,550\n",
      "  RMSE:     68,176,986\n",
      "------------------------------\n",
      "Training Decision Tree (Grid Search)...\n",
      "--- Decision Tree (Grid Search) ---\n",
      "  R² Score: -6.5697\n",
      "  MAE:      8,637,488\n",
      "  RMSE:     187,550,476\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Decision Tree: Bayesian Optimization ---\n",
    "dt_bayes_params = {\n",
    "    'max_depth': Integer(3, 30),\n",
    "    'min_samples_split': Integer(2, 20),\n",
    "    'min_samples_leaf': Integer(1, 10),\n",
    "    'criterion': Categorical(['squared_error', 'absolute_error'])\n",
    "}\n",
    "\n",
    "opt_dt = BayesSearchCV(\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    dt_bayes_params,\n",
    "    n_iter=20, cv=3, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Decision Tree (Bayesian)...\")\n",
    "opt_dt.fit(X_train, y_train)\n",
    "evaluate_and_log(\"Decision Tree\", \"Bayesian\", opt_dt, X_test, y_test)\n",
    "\n",
    "# --- Decision Tree: Grid Search ---\n",
    "dt_grid_params = {\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'min_samples_split': [2, 10],\n",
    "    'min_samples_leaf': [1, 5]\n",
    "}\n",
    "\n",
    "grid_dt = GridSearchCV(\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    dt_grid_params,\n",
    "    cv=3, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Decision Tree (Grid Search)...\")\n",
    "grid_dt.fit(X_train, y_train)\n",
    "evaluate_and_log(\"Decision Tree\", \"Grid Search\", grid_dt, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "929ec690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: home_price_cleaned_first_encode.csv\n",
      "Shape: (20131, 15)\n",
      "Columns: ['Net_Metrekare', 'Brüt_Metrekare', 'Oda_Sayısı', 'Bulunduğu_Kat', 'Eşya_Durumu', 'Binanın_Yaşı', 'Isıtma_Tipi', 'Fiyat', 'Şehir', 'Binanın_Kat_Sayısı', 'Kullanım_Durumu', 'Yatırıma_Uygunluk', 'Takas', 'Tapu_Durumu', 'Banyo_Sayısı']\n",
      "Fiyat stats (before cleaning):\n",
      "count    2.013100e+04\n",
      "mean     4.656591e+06\n",
      "std      7.170283e+07\n",
      "min      2.000000e+04\n",
      "25%      1.639500e+06\n",
      "50%      2.300000e+06\n",
      "75%      3.300000e+06\n",
      "max      7.500000e+09\n",
      "Name: Fiyat, dtype: float64\n",
      "After dropping NaN Fiyat: (20131, 15)\n",
      "Outlier cut: [434,650 , 28,000,000]  (quantiles 0.005, 0.995)\n",
      "After outlier trimming: (19933, 15)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[39m, in \u001b[36m_na_arithmetic_op\u001b[39m\u001b[34m(left, right, op, is_cmp)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(op, a, b, use_numexpr)\u001b[39m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[32m    241\u001b[39m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[39m, in \u001b[36m_evaluate_standard\u001b[39m\u001b[34m(op, op_str, a, b)\u001b[39m\n\u001b[32m     72\u001b[39m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for /: 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[144]\u001b[39m\u001b[32m, line 105\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# floor ratio: floor / total floors (if available)\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mBulunduğu_Kat\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df.columns) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mBinanın_Kat_Sayısı\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df.columns):\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mfloor_ratio\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBulunduğu_Kat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBinanın_Kat_Sayısı\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnan\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mfloor_ratio\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mfloor_ratio\u001b[39m\u001b[33m\"\u001b[39m].fillna(df[\u001b[33m\"\u001b[39m\u001b[33mfloor_ratio\u001b[39m\u001b[33m\"\u001b[39m].median())\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# Building age bucket (simple)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:210\u001b[39m, in \u001b[36mOpsMixin.__truediv__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__truediv__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__truediv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtruediv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:6154\u001b[39m, in \u001b[36mSeries._arith_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[32m   6153\u001b[39m     \u001b[38;5;28mself\u001b[39m, other = \u001b[38;5;28mself\u001b[39m._align_for_op(other)\n\u001b[32m-> \u001b[39m\u001b[32m6154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:1391\u001b[39m, in \u001b[36mIndexOpsMixin._arith_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   1388\u001b[39m     rvalues = np.arange(rvalues.start, rvalues.stop, rvalues.step)\n\u001b[32m   1390\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(\u001b[38;5;28mall\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1391\u001b[39m     result = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(result, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:283\u001b[39m, in \u001b[36marithmetic_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    279\u001b[39m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    281\u001b[39m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[32m    282\u001b[39m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     res_values = \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:227\u001b[39m, in \u001b[36m_na_arithmetic_op\u001b[39m\u001b[34m(left, right, op, is_cmp)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    221\u001b[39m         left.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    222\u001b[39m     ):\n\u001b[32m   (...)\u001b[39m\u001b[32m    225\u001b[39m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[32m    226\u001b[39m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m         result = \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:163\u001b[39m, in \u001b[36m_masked_arith_op\u001b[39m\u001b[34m(x, y, op)\u001b[39m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# See GH#5284, GH#5035, GH#19448 for historical reference\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m         result[mask] = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(y):\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# model_pipeline.py\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ---------------------------\n",
    "# Configuration\n",
    "# ---------------------------\n",
    "DATA_PATH = \"home_price_cleaned_first_encode.csv\"  # change if needed\n",
    "OUTPUT_DIR = \"model_output\"\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Utility functions\n",
    "# ---------------------------\n",
    "def print_scores(y_true, y_pred, label=\"Model\"):\n",
    "    # compute on original scale (y_true, y_pred are original-scale)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f\"--- {label} ---\")\n",
    "    print(f\"  R² Score: {r2:.4f}\")\n",
    "    print(f\"  MAE:      {mae:,.0f}\")\n",
    "    print(f\"  RMSE:     {rmse:,.0f}\")\n",
    "    print(\"------------------------------\")\n",
    "    return {\"r2\": r2, \"mae\": mae, \"rmse\": rmse}\n",
    "\n",
    "def evaluate_and_report(model, X_test, y_test_log, scaler=None, label=\"Model\"):\n",
    "    # model predicts log1p prices (we train on log1p). Convert back with expm1.\n",
    "    y_pred_log = model.predict(X_test)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_true = np.expm1(y_test_log)\n",
    "    return print_scores(y_true, y_pred, label=label)\n",
    "\n",
    "# ---------------------------\n",
    "# Load data\n",
    "# ---------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Loaded:\", DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# Quick check: Fiyat must exist\n",
    "if \"Fiyat\" not in df.columns:\n",
    "    raise ValueError(\"Fiyat column not found. Rename your price column to 'Fiyat'.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Ensure Fiyat numeric (clean if necessary)\n",
    "# ---------------------------\n",
    "# If Fiyat is string with thousand separators or currency, try to coerce:\n",
    "if df[\"Fiyat\"].dtype == object:\n",
    "    df[\"Fiyat\"] = (\n",
    "        df[\"Fiyat\"]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[^\\d\\-\\.]\", \"\", regex=True)  # remove non-numeric chars (keeps minus and dot)\n",
    "        .replace(\"\", np.nan)\n",
    "    )\n",
    "df[\"Fiyat\"] = pd.to_numeric(df[\"Fiyat\"], errors=\"coerce\")\n",
    "\n",
    "print(\"Fiyat stats (before cleaning):\")\n",
    "print(df[\"Fiyat\"].describe())\n",
    "\n",
    "# Drop rows without price\n",
    "df = df[df[\"Fiyat\"].notna()].copy()\n",
    "print(\"After dropping NaN Fiyat:\", df.shape)\n",
    "\n",
    "# ---------------------------\n",
    "# Remove extreme outliers (robust clipping)\n",
    "# ---------------------------\n",
    "# We'll remove top 0.5% and bottom 0.5% by price (adjustable)\n",
    "lower_q = 0.005\n",
    "upper_q = 0.995\n",
    "low_val = df[\"Fiyat\"].quantile(lower_q)\n",
    "high_val = df[\"Fiyat\"].quantile(upper_q)\n",
    "print(f\"Outlier cut: [{low_val:,.0f} , {high_val:,.0f}]  (quantiles {lower_q}, {upper_q})\")\n",
    "df = df[(df[\"Fiyat\"] >= low_val) & (df[\"Fiyat\"] <= high_val)].copy()\n",
    "print(\"After outlier trimming:\", df.shape)\n",
    "\n",
    "# ---------------------------\n",
    "# Feature engineering\n",
    "# ---------------------------\n",
    "# Basic features you already have: use them\n",
    "# Add price per m2, price per room, floor ratio, and some simple interactions\n",
    "# But avoid leaking target: compute derived features from existing ones, not from Fiyat.\n",
    "\n",
    "# Ensure Net_Metrekare > 0 to compute price/m2 later (we will use Net_Metrekare only for derived features if >0)\n",
    "df = df[df[\"Net_Metrekare\"].notna() & (df[\"Net_Metrekare\"] > 0)].copy()\n",
    "\n",
    "# Price per m2 (we will compute using Fiyat but only for analysis; not used as a feature)\n",
    "# Instead, create proxies: rooms_per_m2 = Oda_Sayısı / Net_Metrekare\n",
    "df[\"rooms_per_m2\"] = df[\"Oda_Sayısı\"] / df[\"Net_Metrekare\"]\n",
    "\n",
    "# floor ratio: floor / total floors (if available)\n",
    "if (\"Bulunduğu_Kat\" in df.columns) and (\"Binanın_Kat_Sayısı\" in df.columns):\n",
    "    df[\"floor_ratio\"] = df[\"Bulunduğu_Kat\"] / (df[\"Binanın_Kat_Sayısı\"].replace({0: np.nan}))\n",
    "    df[\"floor_ratio\"] = df[\"floor_ratio\"].fillna(df[\"floor_ratio\"].median())\n",
    "\n",
    "# Building age bucket (simple)\n",
    "df[\"age_bucket\"] = pd.cut(df[\"Binanın_Yaşı\"].fillna(df[\"Binanın_Yaşı\"].median()),\n",
    "                          bins=[-1,0,5,10,15,25,50,1000],\n",
    "                          labels=False).astype(int)\n",
    "\n",
    "# Fill remaining NaNs in features with median (safe for tree models)\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().any() and col != \"Fiyat\":\n",
    "        med = df[col].median()\n",
    "        df[col] = df[col].fillna(med)\n",
    "\n",
    "# ---------------------------\n",
    "# Prepare target: log transform\n",
    "# ---------------------------\n",
    "df[\"Fiyat_log\"] = np.log1p(df[\"Fiyat\"])\n",
    "\n",
    "# ---------------------------\n",
    "# Feature set selection\n",
    "# ---------------------------\n",
    "# Choose the features to use (exclude target and any columns not meant as input)\n",
    "feature_list = [\n",
    "    \"Net_Metrekare\", \"Brüt_Metrekare\", \"Oda_Sayısı\", \"Bulunduğu_Kat\",\n",
    "    \"Eşya_Durumu\", \"Binanın_Yaşı\", \"Isıtma_Tipi\", \"Şehir\",\n",
    "    \"Binanın_Kat_Sayısı\", \"Kullanım_Durumu\", \"Yatırıma_Uygunluk\", \"Takas\",\n",
    "    \"Tapu_Durumu\", \"Banyo_Sayısı\", \"rooms_per_m2\", \"floor_ratio\", \"age_bucket\"\n",
    "]\n",
    "# keep only those present\n",
    "feature_list = [c for c in feature_list if c in df.columns]\n",
    "print(\"Using features:\", feature_list)\n",
    "\n",
    "X = df[feature_list].copy()\n",
    "y_log = df[\"Fiyat_log\"].copy()\n",
    "groups = df[\"Şehir\"].copy() if \"Şehir\" in df.columns else None\n",
    "\n",
    "# ---------------------------\n",
    "# Train/test split (grouped by city to avoid leakage)\n",
    "# ---------------------------\n",
    "if groups is not None:\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=SEED)\n",
    "    train_idx, test_idx = next(gss.split(X, y_log, groups=groups))\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train_log, y_test_log = y_log.iloc[train_idx], y_log.iloc[test_idx]\n",
    "else:\n",
    "    X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.2, random_state=SEED)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
    "\n",
    "# ---------------------------\n",
    "# Optional scaling for linear models (not necessary for tree models)\n",
    "# ---------------------------\n",
    "# We'll keep scaler in case you want to try linear models later.\n",
    "scaler = StandardScaler()\n",
    "# Fit scaler only on numeric columns (all are numeric here)\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ---------------------------\n",
    "# Model training helpers\n",
    "# ---------------------------\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Decision Tree - small grid search (fast)\n",
    "dt_params = {\n",
    "    \"max_depth\": [6, 10, 15],\n",
    "    \"min_samples_leaf\": [5, 10, 20]\n",
    "}\n",
    "dt = DecisionTreeRegressor(random_state=SEED)\n",
    "dt_gs = GridSearchCV(dt, dt_params, cv=3, scoring=\"r2\", n_jobs=-1, verbose=0)\n",
    "dt_gs.fit(X_train, y_train_log)\n",
    "best_dt = dt_gs.best_estimator_\n",
    "print(\"Decision Tree best params:\", dt_gs.best_params_)\n",
    "results[\"DecisionTree\"] = evaluate_and_report(best_dt, X_test, y_test_log, label=\"Decision Tree (Grid Search)\")\n",
    "joblib.dump(best_dt, os.path.join(OUTPUT_DIR, \"best_decision_tree.joblib\"))\n",
    "\n",
    "# Random Forest - moderate grid (may take time)\n",
    "rf = RandomForestRegressor(random_state=SEED, n_jobs=-1)\n",
    "rf_params = {\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"max_depth\": [12, 18],\n",
    "    \"min_samples_leaf\": [5, 10]\n",
    "}\n",
    "rf_gs = GridSearchCV(rf, rf_params, cv=3, scoring=\"r2\", n_jobs=-1, verbose=0)\n",
    "rf_gs.fit(X_train, y_train_log)\n",
    "best_rf = rf_gs.best_estimator_\n",
    "print(\"Random Forest best params:\", rf_gs.best_params_)\n",
    "results[\"RandomForest\"] = evaluate_and_report(best_rf, X_test, y_test_log, label=\"Random Forest (Grid Search)\")\n",
    "joblib.dump(best_rf, os.path.join(OUTPUT_DIR, \"best_random_forest.joblib\"))\n",
    "\n",
    "# XGBoost - light grid (fast-ish)\n",
    "xgb = XGBRegressor(random_state=SEED, n_jobs=-1, objective=\"reg:squarederror\", verbosity=0)\n",
    "xgb_params = {\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"max_depth\": [6, 10],\n",
    "    \"learning_rate\": [0.05, 0.1]\n",
    "}\n",
    "xgb_gs = GridSearchCV(xgb, xgb_params, cv=3, scoring=\"r2\", n_jobs=-1, verbose=0)\n",
    "xgb_gs.fit(X_train, y_train_log)\n",
    "best_xgb = xgb_gs.best_estimator_\n",
    "print(\"XGBoost best params:\", xgb_gs.best_params_)\n",
    "results[\"XGBoost\"] = evaluate_and_report(best_xgb, X_test, y_test_log, label=\"XGBoost (Grid Search)\")\n",
    "joblib.dump(best_xgb, os.path.join(OUTPUT_DIR, \"best_xgb.joblib\"))\n",
    "\n",
    "# ---------------------------\n",
    "# Compare & feature importances (from best model)\n",
    "# ---------------------------\n",
    "print(\"\\nSummary of results (R2 / MAE / RMSE):\")\n",
    "for name, metrics in results.items():\n",
    "    print(name, metrics)\n",
    "\n",
    "# Choose best model by R2\n",
    "best_model_name = max(results.items(), key=lambda kv: kv[1][\"r2\"])[0]\n",
    "print(\"Best model by R2:\", best_model_name)\n",
    "best_model = {\"DecisionTree\": best_dt, \"RandomForest\": best_rf, \"XGBoost\": best_xgb}[best_model_name]\n",
    "\n",
    "# Feature importance (if model supports)\n",
    "try:\n",
    "    importances = best_model.feature_importances_\n",
    "    fi = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
    "    print(\"\\nTop 15 feature importances:\")\n",
    "    print(fi.head(15).to_string())\n",
    "    fi.to_csv(os.path.join(OUTPUT_DIR, \"feature_importances.csv\"))\n",
    "except Exception as e:\n",
    "    print(\"Feature importance not available:\", e)\n",
    "\n",
    "# ---------------------------\n",
    "# Save scaler for later\n",
    "# ---------------------------\n",
    "joblib.dump(scaler, os.path.join(OUTPUT_DIR, \"scaler.joblib\"))\n",
    "\n",
    "print(\"\\nAll done. Models and artifacts saved to:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ba71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVR (Bayesian)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[102]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      8\u001b[39m opt_svr = BayesSearchCV(\n\u001b[32m      9\u001b[39m     SVR(),\n\u001b[32m     10\u001b[39m     svr_bayes_params,\n\u001b[32m     11\u001b[39m     n_iter=\u001b[32m15\u001b[39m, cv=\u001b[32m3\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m \u001b[38;5;66;03m# Lower iter as SVR is slow\u001b[39;00m\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining SVR (Bayesian)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mopt_svr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m evaluate_and_log(\u001b[33m\"\u001b[39m\u001b[33mSVR\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBayesian\u001b[39m\u001b[33m\"\u001b[39m, opt_svr, X_test, y_test)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# --- SVR: Grid Search ---\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\skopt\\searchcv.py:542\u001b[39m, in \u001b[36mBayesSearchCV.fit\u001b[39m\u001b[34m(self, X, y, groups, callback, **fit_params)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.refit):\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    537\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mBayesSearchCV doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt support a callable refit, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt define an implicit score to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    539\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moptimize\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    540\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m542\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_train_score:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\skopt\\searchcv.py:599\u001b[39m, in \u001b[36mBayesSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter > \u001b[32m0\u001b[39m:\n\u001b[32m    596\u001b[39m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[32m    597\u001b[39m     n_points_adjusted = \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     optim_result, score_name = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_points_adjusted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    606\u001b[39m     n_iter -= n_points\n\u001b[32m    608\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\skopt\\searchcv.py:453\u001b[39m, in \u001b[36mBayesSearchCV._step\u001b[39m\u001b[34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[32m    451\u001b[39m params_dict = [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m all_results = \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[38;5;66;03m# if self.scoring is a callable, we have to wait until here\u001b[39;00m\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# to get the score name\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m score_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\OneDrive\\Desktop\\VS_CODE_FILES\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- SVR: Bayesian Optimization ---\n",
    "svr_bayes_params = {\n",
    "    'C': Real(1e-1, 1e+2, prior='log-uniform'),\n",
    "    'kernel': Categorical(['linear', 'rbf']),\n",
    "    'epsilon': Real(1e-2, 1.0, prior='log-uniform')\n",
    "}\n",
    "\n",
    "opt_svr = BayesSearchCV(\n",
    "    SVR(),\n",
    "    svr_bayes_params,\n",
    "    n_iter=15, cv=3, n_jobs=-1 # Lower iter as SVR is slow\n",
    ")\n",
    "\n",
    "print(\"Training SVR (Bayesian)...\")\n",
    "opt_svr.fit(X_train, y_train)\n",
    "evaluate_and_log(\"SVR\", \"Bayesian\", opt_svr, X_test, y_test)\n",
    "\n",
    "# --- SVR: Grid Search ---\n",
    "svr_grid_params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'epsilon': [0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_svr = GridSearchCV(\n",
    "    SVR(),\n",
    "    svr_grid_params,\n",
    "    cv=3, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training SVR (Grid Search)...\")\n",
    "grid_svr.fit(X_train, y_train)\n",
    "evaluate_and_log(\"SVR\", \"Grid Search\", grid_svr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3662692d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest (Bayesian)...\n",
      "--- Random Forest (Bayesian) ---\n",
      "  R² Score: -0.0012\n",
      "  MAE:      4,395,622\n",
      "  RMSE:     68,209,851\n",
      "------------------------------\n",
      "Training Random Forest (Grid Search)...\n",
      "--- Random Forest (Grid Search) ---\n",
      "  R² Score: -0.0433\n",
      "  MAE:      4,726,320\n",
      "  RMSE:     69,628,511\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Random Forest: Bayesian Optimization ---\n",
    "rf_bayes_params = {\n",
    "    'n_estimators': Integer(50, 200),\n",
    "    'max_depth': Integer(5, 30),\n",
    "    'min_samples_split': Integer(2, 10),\n",
    "    'max_features': Categorical(['sqrt', 1.0])\n",
    "}\n",
    "\n",
    "opt_rf = BayesSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    rf_bayes_params,\n",
    "    n_iter=15, cv=3, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest (Bayesian)...\")\n",
    "opt_rf.fit(X_train, y_train)\n",
    "evaluate_and_log(\"Random Forest\", \"Bayesian\", opt_rf, X_test, y_test)\n",
    "\n",
    "# --- Random Forest: Grid Search ---\n",
    "rf_grid_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'max_features': ['sqrt', 1.0]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    rf_grid_params,\n",
    "    cv=3, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest (Grid Search)...\")\n",
    "grid_rf.fit(X_train, y_train)\n",
    "evaluate_and_log(\"Random Forest\", \"Grid Search\", grid_rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "15eb6c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient Boosting (Bayesian)...\n",
      "--- Gradient Boosting (Bayesian) ---\n",
      "  R² Score: 0.6300\n",
      "  MAE:      861,239\n",
      "  RMSE:     1,783,644\n",
      "------------------------------\n",
      "Training Gradient Boosting (Grid Search)...\n",
      "--- Gradient Boosting (Grid Search) ---\n",
      "  R² Score: 0.6427\n",
      "  MAE:      846,823\n",
      "  RMSE:     1,752,809\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Gradient Boosting: Bayesian Optimization ---\n",
    "gb_bayes_params = {\n",
    "    'n_estimators': Integer(100, 300),\n",
    "    'learning_rate': Real(0.01, 0.2, prior='log-uniform'),\n",
    "    'max_depth': Integer(3, 8),\n",
    "    'subsample': Real(0.6, 1.0)\n",
    "}\n",
    "\n",
    "opt_gb = BayesSearchCV(\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    gb_bayes_params,\n",
    "    n_iter=15, cv=3, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Gradient Boosting (Bayesian)...\")\n",
    "opt_gb.fit(X_train, y_train)\n",
    "evaluate_and_log(\"Gradient Boosting\", \"Bayesian\", opt_gb, X_test, y_test)\n",
    "\n",
    "# --- Gradient Boosting: Grid Search ---\n",
    "gb_grid_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_gb = GridSearchCV(\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    gb_grid_params,\n",
    "    cv=3, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Gradient Boosting (Grid Search)...\")\n",
    "grid_gb.fit(X_train, y_train)\n",
    "evaluate_and_log(\"Gradient Boosting\", \"Grid Search\", grid_gb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f34e1a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost (Bayesian)...\n",
      "--- XGBoost (Bayesian) ---\n",
      "  R² Score: 0.6419\n",
      "  MAE:      855,567\n",
      "  RMSE:     1,754,798\n",
      "------------------------------\n",
      "Training XGBoost (Grid Search)...\n",
      "--- XGBoost (Grid Search) ---\n",
      "  R² Score: 0.6416\n",
      "  MAE:      866,433\n",
      "  RMSE:     1,755,512\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- XGBoost: Bayesian Optimization ---\n",
    "xgb_bayes_params = {\n",
    "    'n_estimators': Integer(100, 500),\n",
    "    'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "    'max_depth': Integer(3, 10),\n",
    "    'subsample': Real(0.6, 1.0),\n",
    "    'colsample_bytree': Real(0.6, 1.0)\n",
    "}\n",
    "\n",
    "opt_xgb = BayesSearchCV(\n",
    "    XGBRegressor(random_state=42, n_jobs=-1),\n",
    "    xgb_bayes_params,\n",
    "    n_iter=20, cv=3, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost (Bayesian)...\")\n",
    "opt_xgb.fit(X_train, y_train)\n",
    "evaluate_and_log(\"XGBoost\", \"Bayesian\", opt_xgb, X_test, y_test)\n",
    "\n",
    "# --- XGBoost: Grid Search ---\n",
    "xgb_grid_params = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 6],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    XGBRegressor(random_state=42, n_jobs=-1),\n",
    "    xgb_grid_params,\n",
    "    cv=3, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost (Grid Search)...\")\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "evaluate_and_log(\"XGBoost\", \"Grid Search\", grid_xgb, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
